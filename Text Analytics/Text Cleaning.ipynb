{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f524e89-ecb1-43e7-8ffd-14ea2e686d8d",
   "metadata": {},
   "source": [
    "# **Working with Text Data - Text Preprocessing**\n",
    "\n",
    "## **Text Preprocessing Steps**\n",
    "\n",
    "Text preprocessing steps include some essential tasks to clean and remove the noise from the avaialbe data\n",
    "\n",
    "1. **Removing Special characters and punctuation**\n",
    "2. **Coverting to Lower case**\n",
    "3. **Tokenization (Sentence Tokenization and Word Tokenization)**\n",
    "4. **Removing stop words**\n",
    "5. **Stemming or Lemmatization**\n",
    "6. **HTML Parsing and cleanup**\n",
    "7. **Spell Correction**\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea1ebb44-0e3a-4ab6-985b-d349f4977d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We're LaRNING1 nATURAL-LANguage-Processing!üòÇüôáüçÜ\n",
      "In this\\ example wE are goINg to LeaRN various text9 preProcessing Steps.\n",
      "I'm GOiNG TO-Be Mr. Rich. \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "C:\\Users\\KUMAR SUNDRAM\\AppData\\Local\\Temp\\ipykernel_37412\\3250862623.py:1: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  raw_test = \"\"\"\n"
     ]
    }
   ],
   "source": [
    "raw_test = \"\"\"\n",
    "We're LaRNING1 nATURAL-LANguage-Processing!üòÇüôáüçÜ\n",
    "In this\\ example wE are goINg to LeaRN various text9 preProcessing Steps.\n",
    "I'm GOiNG TO-Be Mr. Rich. \n",
    "\n",
    "\"\"\"\n",
    "print(raw_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8492af83-8828-4cf4-ad16-9c8d5954c853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f1f416bb-ae27-4fcb-9dd5-5f67c822c851",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Were LaRNING nATURALLANguageProcessingüòÇüôáüçÜ\n",
      "In this example wE are goINg to LeaRN various text preProcessing Steps\n",
      "Im GOiNG TOBe Mr Rich \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = \"\".join([char for char in raw_test if char not in string.punctuation and not char.isdigit()])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6535674-1daf-4e6b-868f-00602b92b2ff",
   "metadata": {},
   "source": [
    "# A more powerful weapon to remove special characters and punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6fe6e7b5-5d2d-4572-8d27-fa05c7a3398a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " We re LaRNING  nATURAL LANguage Processing!    In this  example wE are goINg to LeaRN various text  preProcessing Steps. I m GOiNG TO Be Mr. Rich.   \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "regex = \"[^a-zA-Z.!]\"\n",
    "text = re.sub(regex, \" \", raw_test)\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2c1963-3dd8-42ad-b5b6-30f420f5dca3",
   "metadata": {},
   "source": [
    "# Converting to Lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39849684-6327-40cf-babd-080ec159b39e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " we re larning  natural language processing!    in this  example we are going to learn various text  preprocessing steps. i m going to be mr. rich.   \n"
     ]
    }
   ],
   "source": [
    "text = text.lower()\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66454660-f443-4561-bf0e-68064a3ad461",
   "metadata": {},
   "source": [
    "# Tokenization (Sentence Tokenization and Word Tokenization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2286389-78e6-4e39-b8d1-55c18d807e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'we', 're', 'larning', '', 'natural', 'language', 'processing!', '', '', '', 'in', 'this', '', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', '', 'preprocessing', 'steps.', 'i', 'm', 'going', 'to', 'be', 'mr.', 'rich.', '', '', '']\n"
     ]
    }
   ],
   "source": [
    "words = text.split(\" \")\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4aa2655-3fbe-4bae-b912-14d7ea600ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' we re larning  natural language processing!    in this  example we are going to learn various text  preprocessing steps', ' i m going to be mr', ' rich', '   ']\n"
     ]
    }
   ],
   "source": [
    "sentences = text.split(\".\")\n",
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5575dffd-51ac-4c41-81db-8831487e7037",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27015668-5727-479b-aa77-c57ab1df429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "05b28a89-b8b8-46d3-95e1-24bf64192ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\KUMAR\n",
      "[nltk_data]     SUNDRAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37f4fe51-aa3a-4057-ae21-dd3317a3fab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' we re larning  natural language processing!', 'in this  example we are going to learn various text  preprocessing steps.', 'i m going to be mr. rich.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "my_sent = sent_tokenize(text)\n",
    "print(my_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6a767f01-4d49-4cd6-b910-09e349b70866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 're', 'larning', 'natural', 'language', 'processing', '!', 'in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'preprocessing', 'steps', '.', 'i', 'm', 'going', 'to', 'be', 'mr.', 'rich', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "words = word_tokenize(text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "391ef41e-9ca3-40b0-9cdc-44ecc87c6f3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' we re larning  natural language processing!    in this  example we are going to learn various text  preprocessing steps. i m going to be mr. rich.   '"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c57f5bf-965f-439d-be80-91650ad111ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 're', 'larning', 'natural', 'language', 'processing', '!']\n",
      "['in', 'this', 'example', 'we', 'are', 'going', 'to', 'learn', 'various', 'text', 'preprocessing', 'steps', '.']\n",
      "['i', 'm', 'going', 'to', 'be', 'mr.', 'rich', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "for sentence in sent_tokenize(text):\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c786adf-371f-47a6-a6f5-134531bf2c75",
   "metadata": {},
   "source": [
    "# Removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7855f77d-9640-4d15-ae3d-8b575f077243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\KUMAR\n",
      "[nltk_data]     SUNDRAM\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6006217a-0659-47a3-b801-74d72020413a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of stopwords\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(\"List of stopwords\")\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ef904685-cc21-4b43-913e-4cb2ac773b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' we re larning  natural language processing!    in this  example we are going to learn various text  preprocessing steps. i m going to be mr. rich.   '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0f6cd79a-658f-4e9e-89a9-309c60716643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['larning', 'natural', 'language', 'processing', '!', 'example', 'going', 'learn', 'various', 'text', 'preprocessing', 'steps', '.', 'going', 'mr.', 'rich', '.']\n"
     ]
    }
   ],
   "source": [
    "# Removing stop words\n",
    "words = [word for word in words if word not in stopwords.words('english')]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d942cae0-89ef-41e7-ad48-9705949c8290",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b2bc93e5-35b7-47ab-8c3e-83970f5c6e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['larn', 'natur', 'languag', 'process', '!', 'exampl', 'go', 'learn', 'variou', 'text', 'preprocess', 'step', '.', 'go', 'mr.', 'rich', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "clean_tokens_stem = [stemmer.stem(word) for word in words]\n",
    "print(clean_tokens_stem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b60179-e5ae-41d0-a50a-bc755c3abb2a",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "398aabd1-3040-4fba-9065-b08888f9e0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['larning', 'natural', 'language', 'processing', '!', 'example', 'going', 'learn', 'various', 'text', 'preprocessing', 'step', '.', 'going', 'mr.', 'rich', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "clean_tokens_lem = [lemmatizer.lemmatize(word) for word in words]\n",
    "print(clean_tokens_lem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470445fe-e6b9-4338-8254-d7a050f7efbe",
   "metadata": {},
   "source": [
    "# Putting all the steps together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c29173d7-196f-4306-ba77-4291ab7573b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We are Learning Machine Learning $</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Procesing Natural - Language data.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 machine - learning algorithms.We ARE Mimici...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0                 We are Learning Machine Learning $\n",
       "1                 Procesing Natural - Language data.\n",
       "2  10 machine - learning algorithms.We ARE Mimici..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "text = [\"We are Learning Machine Learning $\", \"Procesing Natural - Language data.\", \"10 machine - learning algorithms.\"\n",
    "        \"We ARE Mimicing natural intelligence\"]\n",
    "df = pd.DataFrame({'text' : text})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5f2dc761-ce85-41e7-9551-d56f3b80da0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def clean(doc):\n",
    "    regex = \"[^a-zA-Z!]\"\n",
    "    doc = re.sub(regex, \" \", doc)\n",
    "\n",
    "    doc = doc.lower()\n",
    "\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_token = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatizer_tokens = [lemmatizer.lemmatize(token) for token in filtered_token]\n",
    "\n",
    "    return \" \".join(lemmatizer_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a3c20ced-9e8c-4d71-8585-c576000abbb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We are Learning Machine Learning $</td>\n",
       "      <td>learning machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Procesing Natural - Language data.</td>\n",
       "      <td>procesing natural language data</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10 machine - learning algorithms.We ARE Mimici...</td>\n",
       "      <td>machine learning algorithm mimicing natural in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                 We are Learning Machine Learning $   \n",
       "1                 Procesing Natural - Language data.   \n",
       "2  10 machine - learning algorithms.We ARE Mimici...   \n",
       "\n",
       "                                          clean_text  \n",
       "0                          learning machine learning  \n",
       "1                    procesing natural language data  \n",
       "2  machine learning algorithm mimicing natural in...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'] = df['text'].apply(lambda x : clean(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6f6a0662-06a3-433b-97f0-5855152fa60d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine learning algorithm mimicing natural intelligence'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dab4a7-4416-457e-80fd-0f540cdf5399",
   "metadata": {},
   "source": [
    "# Bag of word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1a510c0b-ad0a-436b-ae26-76ac5ba2b11a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Shape of text_dtm (# of docs, # of unique vocabulary): (3, 9)\n",
      "Vocab : ['algorithm' 'data' 'intelligence' 'language' 'learning' 'machine'\n",
      " 'mimicing' 'natural' 'procesing']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow_vect = CountVectorizer()\n",
    "text_dtm = bow_vect.fit_transform(df['clean_text'])\n",
    "print()\n",
    "print(f\"Shape of text_dtm (# of docs, # of unique vocabulary): {text_dtm.shape}\")\n",
    "print(f\"Vocab : {bow_vect.get_feature_names_out()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "17d2bae6-1d20-4e8b-9ce1-5977c51e18b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>data</th>\n",
       "      <th>intelligence</th>\n",
       "      <th>language</th>\n",
       "      <th>learning</th>\n",
       "      <th>machine</th>\n",
       "      <th>mimicing</th>\n",
       "      <th>natural</th>\n",
       "      <th>procesing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   algorithm  data  intelligence  language  learning  machine  mimicing  \\\n",
       "0          0     0             0         0         2        1         0   \n",
       "1          0     1             0         1         0        0         0   \n",
       "2          1     0             1         0         1        1         1   \n",
       "\n",
       "   natural  procesing  \n",
       "0        0          0  \n",
       "1        1          1  \n",
       "2        1          0  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(text_dtm.toarray(), columns=bow_vect.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eca27e9-e988-4b6a-b4dc-578ef7564c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9be2d2-2927-4e3e-8061-bd713f009c78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9c7a7-4fab-4cf8-8747-f588cda1522f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66d7004-29a4-416d-b502-3746f1ab35f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb7545a-34d4-449a-91b1-ad00ca8431ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
